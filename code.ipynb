{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Create the 'data' directory if it doesn't exist\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "# Download the first file\n",
    "url1 = 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/10q/uber_10q_march_2022.pdf'\n",
    "file_path1 = './data/uber_10q_march_2022.pdf'\n",
    "response1 = requests.get(url1)\n",
    "with open(file_path1, 'wb') as file:\n",
    "    file.write(response1.content)\n",
    "\n",
    "# Download the second file\n",
    "url2 = 'https://meetings.wmo.int/Cg-19/PublishingImages/SitePages/FINAC-43/7%20-%20EC-77-Doc%205%20Financial%20Statements%20for%202022%20(FINAC).pptx'\n",
    "file_path2 = './data/presentation.pptx'\n",
    "response2 = requests.get(url2)\n",
    "with open(file_path2, 'wb') as file:\n",
    "    file.write(response2.content)\n",
    "\n",
    "print('Files downloaded successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio  # noqa: E402\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the LLAMA_CLOUD_API_KEY\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the LLAMAPARSE\n",
    "from llama_parse import LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "llamaparse_api_key = os.getenv('LLAMA_CLOUD_API_KEY')\n",
    "#llamaparse_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for the documents parse using LlamaParse using Cloud\n",
    "#llama_parse_documents = LlamaParse(api_key=llamaparse_api_key, result_type=\"markdown\").load_data(\"./data/presentation.pptx\")\n",
    "#llama_parse_documents = LlamaParse(api_key=llamaparse_api_key, result_type=\"markdown\").load_data(\"./data/uber_10q_march_2022.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defiing the function to tload parsed data if available, or parse if not available\n",
    "def laod_or_parse_data():\n",
    "    data_file = \"./data/parsed_data.pkl\"\n",
    "\n",
    "    if os.path.exists(data_file):\n",
    "        with open(data_file, \"rb\") as f:\n",
    "            parsed_data = pickle.load(f)\n",
    "    #If the file does not exist, parse the data\n",
    "    else:\n",
    "        llama_parse_documents = LlamaParse(api_key = llamaparse_api_key, result_type=\"markdown\").load_data([\"./data/presentation.pptx\",\"./data/uber_10q_march_2022.pdf\"])\n",
    "\n",
    "        #Save the parsed data of the llama_parse_documents\n",
    "        with open(data_file, \"wb\") as f:\n",
    "            pickle.dump(llama_parse_documents, f)\n",
    "\n",
    "        #Set the parsed data to the variable\n",
    "        parsed_data = llama_parse_documents\n",
    "\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the function to either load or parse the data\n",
    "llama_parse_documents = laod_or_parse_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llama_parse_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Document\\n\\n# UNITED STATES SECURITIES AND EXCHANGE COMMISSION Washington, D.C. 20549\\n\\n## FORM 10-Q\\n\\n(Mark One) â˜’ QUARTERLY REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 193'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_parse_documents[0].text[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(llama_parse_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the parsed data tot he qdrant vector stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "import qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_url = os.getenv(\"QDRANT_URL\")\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastEmbedEmbedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faaed8c18afc496fb01d9897452e4878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting embed_model other than openAI \n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Groq API\n",
    "\n",
    "from llama_index.llms.groq import Groq\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Groq(model=\"mixtral-8x7b-32768\", api_key=groq_api_key)\n",
    "#llm = Groq(model=\"gemma-7b-it\", api_key=groq_api_key)\n",
    "#llm = Groq(model=\"llama2-70b-4096\", api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Ollama #######\n",
    "## Setting LLM other than openAI \n",
    "Settings.llm = llm\n",
    "\n",
    "client = qdrant_client.QdrantClient(api_key=qdrant_api_key, url=qdrant_url,)\n",
    "\n",
    "vector_store = QdrantVectorStore(client = client, collection_name='qdrant_url')\n",
    "Storage_Context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(documents=llama_parse_documents, storage_context=Storage_Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context information does not provide the letter of credit as of December 31, 2021.\n"
     ]
    }
   ],
   "source": [
    "### PERSIST_INDEX ####\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "query = \"What is the letter of credit AS of December 31, 2021\"\n",
    "response = query_engine.query(query)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
